{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we'll take data from http://yann.lecun.com/exdb/mnist/ for digits\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic idea of the NN\n",
    "#\n",
    "# repeat milions of times the two steps bellow:\n",
    "#\n",
    "# step 1: feed froward\n",
    "#\n",
    "# we get input image -> send it to input layer -> weights \n",
    "#   -> hidden layer 1 -> weights \n",
    "#   -> hidden layer 2 -> weights \n",
    "#   -> output \n",
    "#\n",
    "# step 2: backpropagation\n",
    "#\n",
    "# compare output to intended outpuntt (we have indended from the data) -> cost function (corss entropy)\n",
    "# cross entropy wiki: https://en.wikipedia.org/wiki/Cross_entropy\n",
    "#\n",
    "# optimization function -> attempts to mimzie cost function by manipulating the weights\n",
    "# AdamOptimizer, SGD (gradient descnet) etc\n",
    "# \n",
    "# feed forward + backpropagation = epoc (one iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# we already have the data available in the examples file\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# one_hot = True means we represent the data in a vector way, see below\n",
    "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)\n",
    "\n",
    "# 10 classes, from 0 to 9\n",
    "# 0 = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] because one_hot=true in read_data_sets\n",
    "# 1 = [0, 1, ....] etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we declare the number of newurons for each layer to be used \n",
    "# in configuration for tensureflow\n",
    "\n",
    "n_nodes_hl1 = 500\n",
    "n_nodes_hl2 = 620\n",
    "n_nodes_hl3 = 300\n",
    "\n",
    "n_classes = 10\n",
    "\n",
    "# batch size = how many images we will send once before we backpropagate\n",
    "# how many photos we send before we change weights in the neural network\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we declare inputs for the image. In tensorflow we declare the inputs\n",
    "# as these placeholder which will be treated as input 'gates' of sorts\n",
    "# when we run the program\n",
    "\n",
    "# the height x width of the image, so the number of pixels we are sending \n",
    "x = tf.placeholder(tf.float32, [None, 28*28])\n",
    "\n",
    "# y is what will be placing as expected values\n",
    "y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# each layer in the network will have one weight and one baias for each 'neuron'\n",
    "# each neuron will receive all the inputs. \n",
    "# \n",
    "# this means that for each input value, we will run all the wieghts and add all the baiases?\n",
    "def neural_network_layer_initialisation(input_count, output_count):\n",
    "    layer_configuration = {\n",
    "        'weigths': tf.Variable(\n",
    "            # gets a random matrix of values, with inputcount rows and outputcount columns\n",
    "            tf.random_normal([\n",
    "                input_count, output_count\n",
    "            ])\n",
    "        ),\n",
    "        'biases': tf.Variable(\n",
    "            # gets a random row of values, of output_count\n",
    "            tf.random_normal(\n",
    "                [output_count]\n",
    "            )\n",
    "        )\n",
    "    }\n",
    "    return layer_configuration\n",
    "    \n",
    "# cool reason for biases. Because we might have 0 input, and 0 * weights = 0 all the time. \n",
    "# with baias, we might end up with neurons being triggered regardless of 0. \n",
    "# y = w * x + b (wieghts multiplied by input, adding bias afterwards) => output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network_model(data): \n",
    "    # first layer gets the image, so 784 pixel values and returns one value out of \n",
    "    # each neuron of the first layer\n",
    "    hidden_1_layer = neural_network_layer_initialisation(784, n_nodes_hl1)\n",
    "    # second layer gets the input from first layer and outputs a set of values\n",
    "    # equal with the number of neurons on the second layer\n",
    "    hidden_2_layer = neural_network_layer_initialisation(n_nodes_hl1, n_nodes_hl2)\n",
    "\n",
    "    hidden_3_layer = neural_network_layer_initialisation(n_nodes_hl2, n_nodes_hl3)\n",
    "    \n",
    "    # output get the values from the third layer and outputs one number for each n_classes\n",
    "    # we have. We will train the network and force it to return the one_hot=True representation\n",
    "    # we discussed above, so for 0, we would expect the output to be [1, 0, 0 ...]\n",
    "    output_layer = neural_network_layer_initialisation(n_nodes_hl3, n_classes)    \n",
    "    \n",
    "    \n",
    "    # we now describe in therms that tensurflow understand the way the layers \n",
    "    # propagate data, in terms of matrix computations\n",
    "    l1 = tf.add(\n",
    "        tf.matmul(data, hidden_1_layer['weigths']), hidden_1_layer['biases']\n",
    "    )\n",
    "    ## todo read about\n",
    "    l1 = tf.nn.relu(l1)\n",
    "    \n",
    "    \n",
    "    # layer two takes layer 1 output and does its thing\n",
    "    l2 = tf.add(\n",
    "        tf.matmul(l1, hidden_2_layer['weigths']), hidden_2_layer['biases']\n",
    "    )\n",
    "    l2 = tf.nn.relu(l2)\n",
    "    \n",
    "    \n",
    "    # layer two takes layer 2 output and does its thing\n",
    "    l3 = tf.add(\n",
    "        tf.matmul(l2, hidden_3_layer['weigths']), hidden_3_layer['biases']\n",
    "    )\n",
    "    l3 = tf.nn.relu(l3)\n",
    "    \n",
    "    print output_layer\n",
    "    # output layer takes layer 3 output and does its thing\n",
    "    output = tf.matmul(l3, output_layer['weigths']) + output_layer['biases']\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_neural_netowrk(x, y, hm_epochs):\n",
    "    \n",
    "    # the final step of the configuration, we specify how the training session would behave\n",
    "    prediction = neural_network_model(x)\n",
    "    \n",
    "    cost = tf.reduce_mean( \n",
    "        tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y) \n",
    "    )\n",
    "    \n",
    "    # learning_rate = 0.001 is the default learning rate for this optimizer\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    \n",
    "    correct = tf.equal(tf.argmax(prediction,1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "    \n",
    "    # we begin the training\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        for epoch in range(1, hm_epochs):\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            \n",
    "            for _ in range(int(mnist.train.num_examples/batch_size)):\n",
    "                # it so happens that the minst data set gives us batches of images\n",
    "                # via this helper function so we can focus on JUST the AI implementation\n",
    "                e_x, e_y = mnist.train.next_batch(batch_size)\n",
    "                \n",
    "                a, c = sess.run([optimizer, cost], feed_dict = { x:e_x, y:e_y })\n",
    "                \n",
    "                epoch_loss += c\n",
    "            \n",
    "            print('Epoc', epoch, 'complete out of', hm_epochs, 'loss:', epoch_loss)\n",
    "            print('Accuracy:', accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "        \n",
    "        \n",
    "        print('Accuracy:', accuracy.eval({x:mnist.test.images, y:mnist.test.labels}))\n",
    "        \n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weigths': <tf.Variable 'Variable_30:0' shape=(300, 10) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_31:0' shape=(10,) dtype=float32_ref>}\n",
      "WARNING:tensorflow:From <ipython-input-14-51c898a36086>:18: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "('Epoc', 1, 'complete out of', 20, 'loss:', 1346544.8933334351)\n",
      "('Accuracy:', 0.90319997)\n",
      "('Epoc', 2, 'complete out of', 20, 'loss:', 330655.83704280853)\n",
      "('Accuracy:', 0.91659999)\n",
      "('Epoc', 3, 'complete out of', 20, 'loss:', 181692.12311267853)\n",
      "('Accuracy:', 0.93169999)\n",
      "('Epoc', 4, 'complete out of', 20, 'loss:', 108693.57877734303)\n",
      "('Accuracy:', 0.9357)\n",
      "('Epoc', 5, 'complete out of', 20, 'loss:', 66982.58819231391)\n",
      "('Accuracy:', 0.94220001)\n",
      "('Epoc', 6, 'complete out of', 20, 'loss:', 41992.779615871608)\n",
      "('Accuracy:', 0.9447)\n",
      "('Epoc', 7, 'complete out of', 20, 'loss:', 26549.645611868444)\n",
      "('Accuracy:', 0.94459999)\n",
      "('Epoc', 8, 'complete out of', 20, 'loss:', 19356.023478407918)\n",
      "('Accuracy:', 0.95109999)\n",
      "('Epoc', 9, 'complete out of', 20, 'loss:', 18622.694955962561)\n",
      "('Accuracy:', 0.94989997)\n",
      "('Epoc', 10, 'complete out of', 20, 'loss:', 15006.179970453206)\n",
      "('Accuracy:', 0.94910002)\n",
      "('Epoc', 11, 'complete out of', 20, 'loss:', 13355.164251687298)\n",
      "('Accuracy:', 0.95700002)\n",
      "('Epoc', 12, 'complete out of', 20, 'loss:', 12279.67369393941)\n",
      "('Accuracy:', 0.95590001)\n",
      "('Epoc', 13, 'complete out of', 20, 'loss:', 12805.51043146968)\n",
      "('Accuracy:', 0.95679998)\n",
      "('Epoc', 14, 'complete out of', 20, 'loss:', 11101.067129439325)\n",
      "('Accuracy:', 0.95660001)\n",
      "('Epoc', 15, 'complete out of', 20, 'loss:', 10824.642445527752)\n",
      "('Accuracy:', 0.95670003)\n",
      "('Epoc', 16, 'complete out of', 20, 'loss:', 9421.9834428559989)\n",
      "('Accuracy:', 0.95539999)\n",
      "('Epoc', 17, 'complete out of', 20, 'loss:', 10689.92632381618)\n",
      "('Accuracy:', 0.9605)\n",
      "('Epoc', 18, 'complete out of', 20, 'loss:', 7536.7385111079111)\n",
      "('Accuracy:', 0.96109998)\n",
      "('Epoc', 19, 'complete out of', 20, 'loss:', 6889.2118239450492)\n",
      "('Accuracy:', 0.95920002)\n",
      "('Accuracy:', 0.95920002)\n"
     ]
    }
   ],
   "source": [
    "train_neural_netowrk(x, y, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
